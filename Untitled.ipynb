{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdacf7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torpy\n",
      "  Downloading torpy-1.1.6.tar.gz (90 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.7/90.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: cryptography>=3.2 in /Users/berkaniyacine/anaconda3/lib/python3.11/site-packages (from torpy) (41.0.2)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/berkaniyacine/anaconda3/lib/python3.11/site-packages (from cryptography>=3.2->torpy) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /Users/berkaniyacine/anaconda3/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=3.2->torpy) (2.21)\n",
      "Building wheels for collected packages: torpy\n",
      "  Building wheel for torpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torpy: filename=torpy-1.1.6-py3-none-any.whl size=84248 sha256=cf35b8013d8934ca8337395a30b34056b74d5f290acd95bddb45257909c0742a\n",
      "  Stored in directory: /Users/berkaniyacine/Library/Caches/pip/wheels/df/63/8b/2942517ca245ffac8f6658c5687e8f1087d8caf85c828471c1\n",
      "Successfully built torpy\n",
      "Installing collected packages: torpy\n",
      "Successfully installed torpy-1.1.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torpy==1.1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43413d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veuillez saisir votre requête : cancer analysis\n",
      "Langue détectée ==> Anglais\n",
      "Nombre de résultats souhaités : 3\n",
      "Fichier CSV enregistré avec succès.\n",
      "Article non disponible\n",
      "Erreur lors du téléchargement du PDF https://sci-hub.st/downloads/2022-11-05/d16c/wang2022.pdf: 404 Client Error: Not Found for url: https://sci-hub.st/downloads/2022-11-05/d16c/wang2022.pdf\n",
      "Nombre total d'articles téléchargés avec succès : 1\n"
     ]
    }
   ],
   "source": [
    "from Scraper_PubMed import *\n",
    "#from Scraper_pdf import *\n",
    "from tor_py import *\n",
    "from utils import *\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Fonction principale pour exécuter le programme de recherche et de téléchargement d'articles scientifiques.\n",
    "    \"\"\"\n",
    "    # URL de l'API PubMed pour effectuer la recherche\n",
    "    url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&retmode=json&retmax=NUM&sort=relevance&term=KEYWORD\"\n",
    "    \n",
    "    # Saisie de la requête de l'utilisateur\n",
    "    mot_cle = saisie_requete()\n",
    "    \n",
    "    # Détection de la langue de la requête\n",
    "    langue = detect_language(mot_cle)\n",
    "    \n",
    "    # Sélection et extraction des mots-clés en fonction de la langue détectée\n",
    "    mots_cles_format = selection_extraction_mots_cles(mot_cle, langue)\n",
    "    \n",
    "    # Saisie du nombre d'articles souhaités par l'utilisateur\n",
    "    num = saisie_nombre_resultats()\n",
    "    \n",
    "    # Construction de l'URL de la requête avec les paramètres fournis par l'utilisateur\n",
    "    url = construction_url_requete(url, num, mots_cles_format)\n",
    "    \n",
    "    # Gestion du contexte SSL pour éviter les avertissements\n",
    "    gestion_contexte_SSL()\n",
    "    \n",
    "    # Récupération des identifiants PubMed des articles correspondant à la requête\n",
    "    pubmed_ids = get_pubmed_ids(url, num)\n",
    "    \n",
    "    # Récupération des données des articles à partir de leurs identifiants PubMed\n",
    "    articles_data = get_article_data(pubmed_ids)\n",
    "    \n",
    "    # Enregistrement des données des articles dans un fichier CSV\n",
    "    file_name = enregistrement_articles_csv(articles_data, mots_cles_format, num)\n",
    "    \n",
    "    # Création d'un dossier pour enregistrer les fichiers PDF\n",
    "    name_folder = NameFolder(mots_cles_format, num)\n",
    "    create_folder(name_folder)\n",
    "        \n",
    "    # Téléchargement des fichier pdf \n",
    "    download_pdf(file_name, name_folder)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01528adc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b47b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "from init import *\n",
    "\n",
    "\n",
    "# Liste des User-Agents pour simuler différents navigateurs lors des requêtes HTTP\n",
    "user_agents = [\n",
    "    \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1\",\n",
    "    \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:55.0) Gecko/20100101 Firefox/55.0\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.101 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1\",\n",
    "    \"Mozilla/5.0 (X11; CrOS i686 2268.111.0) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.57 Safari/536.11\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1092.0 Safari/536.6\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1090.0 Safari/536.6\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/19.77.34.5 Safari/537.1\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.9 Safari/536.5\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.0) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.36 Safari/536.5\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3\",\n",
    "    \"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_0) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.0 Safari/536.3\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Fonction pour créer un dossier s'il n'existe pas déjà\n",
    "def create_folder(folder_name):\n",
    "    \"\"\"\n",
    "    Crée un dossier s'il n'existe pas déjà.\n",
    "    \n",
    "    Args:\n",
    "        folder_name (str): Le nom du dossier à créer.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "def traite_query(query):\n",
    "    \"\"\"\n",
    "    Utilise spaCy pour traiter une requête en anglais et la formate pour une recherche.\n",
    "    \n",
    "    Args:\n",
    "        query (str): La requête à traiter.\n",
    "        \n",
    "    Returns:\n",
    "        str: La requête traitée et formatée.\n",
    "    \"\"\"\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(query)\n",
    "    mots_cles = []\n",
    "    for token in doc:\n",
    "        if not token.is_stop and not token.is_punct and token.text.lower():\n",
    "            mots_cles.append(token.text)\n",
    "                \n",
    "    mots_cles_format = '+'.join(mots_cles)\n",
    "    \n",
    "    return mots_cles_format\n",
    "\n",
    "def search_save_pdf(pdf_url, folder_name):\n",
    "    \"\"\"\n",
    "    Recherche et télécharge un fichier PDF à partir d'une URL et l'enregistre dans un dossier spécifié.\n",
    "    \n",
    "    Args:\n",
    "        pdf_url (str): L'URL du fichier PDF à télécharger.\n",
    "        folder_name (str): Le nom du dossier dans lequel enregistrer le fichier PDF.\n",
    "        \n",
    "    Returns:\n",
    "        str: Le chemin du fichier enregistré.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        headers = {\"User-Agent\": rd.choice(user_agents)}\n",
    "        response = requests.get(pdf_url, headers=headers, stream=True)\n",
    "        response.raise_for_status()\n",
    "        file_name = f\"article_{uuid.uuid4()}.pdf\"\n",
    "        file_path = os.path.join(folder_name, file_name)\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        return file_path\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erreur lors du téléchargement du PDF {pdf_url}: {str(e)}\")\n",
    "    except Exception as ex:\n",
    "        print(f\"Une erreur inattendue s'est produite : {str(ex)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def download_pdf(file_name, folder):\n",
    "    \"\"\"\n",
    "    Télécharge les fichiers PDF correspondant à un fichier csv et les enregistre dans un dossier spécifié.\n",
    "    \n",
    "    Args:\n",
    "        file_name (str): Le fichier csv.\n",
    "        folder (str): Le nom du dossier dans lequel enregistrer les fichiers PDF.\n",
    "    \"\"\"\n",
    "    base = pd.read_csv(file_name, usecols=['DOI'])\n",
    "    base.dropna(inplace=True)  # Supprime les lignes vides\n",
    "\n",
    "    base = list(base['DOI'])\n",
    "    base_url = []\n",
    "    sci = \"https://sci-hub.st\"\n",
    "    for i in base:\n",
    "        base_url.append(f\"{sci}/\"+str(i))\n",
    "\n",
    "    article = []\n",
    "    for i in base_url:\n",
    "        response = requests.get(i)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            embed_tag = soup.find('embed', type='application/pdf')\n",
    "            if embed_tag:\n",
    "                download_link = embed_tag['src']\n",
    "                article.append(f\"{sci}{download_link}\")\n",
    "            else:\n",
    "                print(\"Article non disponible\")\n",
    "        else:\n",
    "            print(f\"Erreur lors de la requête HTTP : {response.status_code}\")\n",
    "\n",
    "    pdf_list = [url.split('#')[0] for url in article]\n",
    "\n",
    "    url_list = []\n",
    "    for url in pdf_list:\n",
    "        parts = url.split('/')\n",
    "\n",
    "        for i in range(len(parts) - 1, -1, -1):\n",
    "            if 'sci-hub.st' in parts[i] and 'downloads' not in parts[i]:\n",
    "                pdf_url = '/'.join(parts[i:])\n",
    "                break\n",
    "            elif 'sci-hub.st' in parts[i] and 'downloads' in parts[i]:\n",
    "                pdf_url = '/'.join(parts[i+1:])\n",
    "                break\n",
    "\n",
    "        if pdf_url.startswith('sci-hub.st//'):\n",
    "            pdf_url = pdf_url[len('sci-hub.st//'):]\n",
    "\n",
    "        url_list.append(pdf_url)\n",
    "    num_articles = 0\n",
    "    for url in url_list:\n",
    "      h= str(\"https://\"+url)\n",
    "      file_path = search_save_pdf(h, folder)\n",
    "      if file_path:\n",
    "          num_articles += 1\n",
    "    # return the base64 of the first pdf\n",
    "    with open(file_path, \"rb\") as pdf_file:\n",
    "        encoded_string = base64.b64encode(pdf_file.read())\n",
    "        return encoded_string\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
